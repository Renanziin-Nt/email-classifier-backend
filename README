Email Classifier API

Uma API inteligente para classificação automática de emails em categorias produtivas e improdutivas, com geração de respostas automatizadas usando técnicas de Processamento de Linguagem Natural (NLP) e Machine Learning.
🚀 Funcionalidades

    📨 Classificação de Emails: Identifica se um email é "Produtivo" ou "Improdutivo"

    🤖 Geração de Respostas: Sugere respostas automáticas contextualizadas

    📁 Suporte a Múltiplos Formatos: Processa texto direto, arquivos TXT e PDF

    ⚡ Processamento Assíncrono: Sistema de jobs com polling adaptativo

    🎯 Modelo de ML Integrado: Usa Logistic Regression com TF-IDF para classificação

    🔌 API de IA: Integração com Gemini AI e Hugging Face opcionais

🛠️ Tecnologias Utilizadas

    Python 3.12 - Linguagem principal

    FastAPI - Framework web moderno e rápido

    Scikit-learn - Machine Learning para classificação

    NLTK - Processamento de Linguagem Natural

    Google Gemini AI - Geração de respostas inteligentes (opcional)

    Hugging Face - Modelos de NLP (opcional)

    Uvicorn - Servidor ASGI de alta performance

📦 Instalação
Pré-requisitos

    Python 3.12 ou superior

    pip (gerenciador de pacotes Python)

Configuração do Ambiente

    Clone o repositório:

bash

git clone https://github.com/seu-usuario/email-classifier-backend.git
cd email-classifier-backend

    Crie um ambiente virtual:

bash

python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate     # Windows

    Instale as dependências:

bash

pip install -r requirements.txt

    Baixe os recursos do NLTK:

bash

python -c "
import nltk
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('punkt_tab')
nltk.download('rslp')
print('✅ Recursos NLTK instalados!')
"

    Configure variáveis de ambiente (opcional):

bash

cp .env.example .env
# Edite o .env com suas chaves API

🔧 Configuração
Variáveis de Ambiente

Crie um arquivo .env na raiz do projeto:
env

# Chave da API Gemini (opcional)
GEMINI_API_KEY=your_gemini_api_key_here

# Chave da API Hugging Face (opcional)
HF_API_KEY=your_huggingface_api_key_here

# Configurações do servidor
HOST=0.0.0.0
PORT=8000
DEBUG=True

Chaves API Opcionais

    Gemini AI: Para geração de respostas mais inteligentes

    Hugging Face: Para classificação usando modelos pré-treinados

Nota: O sistema funciona perfeitamente sem essas chaves, usando o modelo ML local.
🚀 Execução
Desenvolvimento
bash

uvicorn app.main:app --reload --host 0.0.0.0 --port 8000

Produção
bash

uvicorn app.main:app --host 0.0.0.0 --port 8000 --workers 4

Com Docker
bash

docker build -t email-classifier-api .
docker run -p 8000:8000 email-classifier-api

📚 API Endpoints
POST /classify-email

Inicia o processamento de um email.

Body options:

    text: Texto direto do email

    file: Arquivo TXT ou PDF (multipart/form-data)

Response:
json

{
  "job_id": "uuid-do-job",
  "status": "pending",
  "message": "Job criado com sucesso"
}

GET /job-status/{job_id}

Verifica o status de um job.

Response:
json

{
  "job_id": "uuid-do-job",
  "status": "completed",
  "progress": 100,
  "current_step": "Processamento concluído",
  "message": "Email classificado com sucesso",
  "result": {
    "category": "Produtivo",
    "suggested_response": "Resposta gerada...",
    "confidence": 0.92,
    "processed_text": "Texto processado...",
    "original_length": 250
  }
}

GET /health

Verifica o status da API.

Response:
json

{
  "status": "healthy",
  "version": "1.0.0",
  "active_jobs": 3
}

DELETE /job/{job_id}

Remove um job da memória.
🧪 Exemplos de Uso
Via cURL

Classificar texto direto:
bash

curl -X POST "http://localhost:8000/classify-email" \
  -H "Content-Type: application/json" \
  -d '{"text": "Preciso de ajuda com um erro no sistema urgente"}'

Classificar arquivo:
bash

curl -X POST "http://localhost:8000/classify-email" \
  -F "file=@email.pdf" \
  -H "Content-Type: multipart/form-data"

Verificar status:
bash

curl "http://localhost:8000/job-status/SEU_JOB_ID_AQUI"

Via Python
python

import requests

# Classificar email
response = requests.post("http://localhost:8000/classify-email", 
    json={"text": "Olá, preciso de suporte técnico"}
)

job_id = response.json()["job_id"]

# Verificar status
status = requests.get(f"http://localhost:8000/job-status/{job_id}")
print(status.json())

🏗️ Estrutura do Projeto
text

email-classifier-backend/
├── app/
│   ├── main.py                 # Aplicação FastAPI principal
│   ├── models/
│   │   ├── __init__.py
│   │   ├── schemas.py          # Modelos Pydantic
│   │   └── ml_model.py         # Modelo de Machine Learning
│   ├── services/
│   │   ├── __init__.py
│   │   ├── ai_service.py       # Serviço de IA principal
│   │   ├── classifier.py       # Classificação de emails
│   │   ├── response_generator.py # Geração de respostas
│   │   └── email_processor.py  # Processamento de texto
│   └── utils/
│       ├── __init__.py
│       └── logging_utils.py    # Utilitários de logging
├── models/
│   └── classifier_model.pkl    # Modelo ML treinado (gerado automaticamente)
├── requirements.txt            # Dependências do projeto
├── .env.example               # Exemplo de variáveis de ambiente
└── README.md                  # Este arquivo

🎯 Modelo de Machine Learning

O sistema utiliza um modelo Logistic Regression com TF-IDF Vectorizer treinado com exemplos de emails produtivos e improdutivos.

Características:

    ✅ Treinado com 40+ exemplos categorizados

    ✅ Validação cruzada integrada

    ✅ Persistência automática (arquivo .pkl)

    ✅ Fallback para análise heurística

🔍 Tipos de Classificação
📈 Emails Produtivos

    Solicitações de suporte técnico

    Problemas e erros reportados

    Dúvidas sobre o sistema

    Solicitações de status

    Questões financeiras

💬 Emails Improdutivos

    Mensagens de agradecimento

    Felicitações e cumprimentos

    Mensagens sociais

    Feedback positivo

    Comunicações informais

⚡ Performance

    Tempo de resposta: < 2 segundos para emails típicos

    Concorrência: Suporte a múltiplos jobs simultâneos

    Escalabilidade: Arquitetura preparada para horizontal scaling

🐛 Solução de Problemas
Erros Comuns

    CORS Blocked: Verifique se o frontend está na lista de origens permitidas

    NLTK Resources: Execute o download dos recursos do NLTK

    Memory Issues: Jobs antigos são automaticamente limpos

Logs e Debug

Ative o modo debug para logs detalhados:
bash

export DEBUG=True
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000

🤝 Contribuição

    Fork o projeto

    Crie uma branch para sua feature (git checkout -b feature/AmazingFeature)

    Commit suas mudanças (git commit -m 'Add some AmazingFeature')

    Push para a branch (git push origin feature/AmazingFeature)

    Abra um Pull Request

📄 Licença

Este projeto está sob a licença MIT. Veja o arquivo LICENSE para detalhes.
🏆 Reconhecimentos

    FastAPI por fornecer um framework web excepcional

    Scikit-learn por ferramentas incríveis de Machine Learning

    Google Gemini por modelos de IA generativa

    Hugging Face por democratizar o NLP